---
title: "Interactive visualization"
author: "Christopher Brehm, Klara Kuhn, Cosima Meyer, and Antje Rosebrock"
output: html_document
---

<!-- ### Read in the data -->
```{r, setup, message=FALSE, warning=FALSE, echo=FALSE}
# set working directory
#setwd("~/Dropbox/Big Data/Data/")

# install necessary packages
# install.packages("install.load")
library(install.load)
packages <-
  c(
    "quanteda",
    "tidyverse",
    "tidytext",
    "reshape2",
    "ggplot2",
    "dplyr",
    "stringr",
    "wordcloud",
    "SnowballC",
    "lubridate",
    "plotly",
    "wesanderson"
    )
install_load(packages)

# # might be required
# devtools::install_github('tidyverse/ggplot2')

# read in csv
fulldata <- read.csv("~/Dropbox/Big Data/fulldata.csv", stringsAsFactors=FALSE)

# for color in plots
cbp1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

```


<!-- ### Prepare corpus -->
```{r, eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# create a text corpus
fulldata <- as.data.frame(fulldata)
corpus_comment <- corpus(as.character(fulldata$textDisplay), docvars = data.frame(group = fulldata$group))

# preprocessing  
corpus_comment_dfm <-
  dfm(
  corpus_comment,
  remove = c(stopwords("english"), stopwords("spanish"),
  "â", "ðÿ"),
  verbose = TRUE,
  remove_punct = TRUE,
  remove_numbers = TRUE
  )

corpus_comment_dfm_trim <- dfm_trim(corpus_comment_dfm, min_docfreq = 2)
```
<!-- ### Sentiment analysis -->


<!-- Again, we need to install the required packages first and do some data preprocessing. -->
```{r, setup2, message=FALSE, warning=FALSE, echo=FALSE}

# preprocessing
comments <- fulldata %>%
  dplyr::group_by(group) %>%
  mutate(line = row_number(),
  comment = cumsum(str_detect(
  textDisplay, regex("^chapter [\\divxlc]",
  ignore_case = TRUE)
  ))) %>%
  ungroup()

tidy_comments <- comments %>%
  unnest_tokens(word, textDisplay)

# stemming
tidy_comments<-tidy_comments %>%
      dplyr::mutate_at("word", dplyr::funs(wordStem((.), language="en")))

# remove white space
tidy_comments$word <- gsub("\\s+","",tidy_comments$word)

# remove numbers
tidy_comments<-tidy_comments[-grep("\\b\\d+\\b", tidy_comments$word),]

# tidytext automatically lowers and removes punctuation

# remove stopwords
cleaned_comments <- tidy_comments %>%
  anti_join(stop_words, by = c("word" = "word")) %>%
  filter(
    !str_detect(word, "â"),
    !str_detect(word, "ðÿ"),
    !str_detect(word, "trump"))
```

<!-- Now proceed with the word clouds.  -->
<!-- We first created a simple word cloud: -->

<!-- ### Plot over time -->

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align="center"}

sentiment_by_time <- cleaned_comments %>%
    # Define a new column using floor_date()
    mutate(date = floor_date(as.Date(publishedAt), unit = "week")) %>%
    # Group by date
    group_by(group, date) %>%
    mutate(total_words = n()) %>%
    ungroup() %>%
    # Implement sentiment analysis using the NRC lexicon
    inner_join(get_sentiments("bing"))

labs <- c("1" = "Fox users", "2" ="MSNBC users", "3" = "Both")

plot1 <- sentiment_by_time %>%
    # Filter for positive and negative words
    filter(sentiment %in% c("positive", "negative")) %>%
    # Count by date, sentiment, and total_words
    count(group, date, sentiment, total_words) %>% 
    # tally() %>% 
    ungroup() %>%
    #group_by(videoId) %>% 
    mutate(percent = n / total_words) %>%
    mutate(perc = percent * 100) %>% 
    # mutate(perc = percent, percent = sprintf("%.2f%%", percent)) %>% 
    # Set up the plot with aes()
    ggplot(aes(date, percent, fill = sentiment)) +
    geom_col(aes(text = paste('Date:', as.Date(date),
                 '<br>Percent: ', sprintf("%.2f%%", perc),
                 '<br>Sentiment: ', sentiment))) + #geom_line(size = 0.5) +
   # geom_smooth(method = "lm", se = FALSE, lty = 2) +
   # expand_limits(y = 0) +
      scale_fill_manual(values=wes_palette("Chevalier1")
) +
    facet_wrap( ~ group, labeller=as_labeller(labs)) + #, ncol=1)
    labs(title = "Comparison of sentiment in comments between user groups (Fox, MSNBC, overlap) over time", x = "Time", y = "Percentage", color= "Sentiment") +
    scale_y_continuous(labels = function(percentage) paste0(percentage*100, "%")) + # Multiply by 100 & add %  
theme_minimal()

ggplotly(plot1, tooltip = c("text")) 
```



